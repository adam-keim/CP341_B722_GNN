{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ce11e47-318b-4293-9c96-d4bda137baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tgn\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09bfa4-93d4-455b-b2ce-56061024d0dd",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff019ff-4eff-4a71-95db-396335a521d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e595425e-89c1-45a3-8278-325bdcd900f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c465aa0-7fde-4b4a-a1e6-c2492b8612ae",
   "metadata": {},
   "source": [
    "# Training and Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "835d60e2-6926-4a3f-a974-168da5bf72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer, loss_fn):\n",
    "    \n",
    "    for _, batch in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        model_out = model(batch.x.float(), batch.edge_index)\n",
    "        loss = loss_fn(torch.squeeze(model_out), batch.y.float())\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99e97a4-66b6-4ce8-93ec-8383c0f2cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f36fa-7bc9-4f00-8f61-b794918b554d",
   "metadata": {},
   "source": [
    "# Message Passing Pyg Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbeff239-2f3b-48e6-9be5-d85ec1856d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = torch.load('tensor_list.pt')\n",
    "\n",
    "# data_list = torch.load('tensor_list_node_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c323bc2-12f4-419d-b404-2ec27e2f4b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are labelling every node with the graph label\n",
    "data_list[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "973f50e7-c083-40f2-8170-871700e50bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0e6ba2a-a007-4e43-b4d0-b518ae5a5858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num model params: 3\n"
     ]
    }
   ],
   "source": [
    "model = GCNConv(2,1)\n",
    "print('num model params:', count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4efd0-1aa0-478a-804d-ff85a5a929bb",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80a0daae-b21b-4b8d-b7a7-6019c1660ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [13:40<00:00,  2.49it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method tqdm.close of <tqdm.std.tqdm object at 0x7f8f34381ca0>>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2000\n",
    "\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(total = epochs, position=0, leave=True)\n",
    "for epoch in range(epochs):\n",
    "    losses.append(train_one_epoch(model, loader, optimizer, loss_fn))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63a81f91-96bf-4d3f-9cd4-d77aaca9b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim_GCN_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a9266c3-cc99-4329-880f-4341c30221c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2e21aff-12f6-4829-88d0-873ee889cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNConv(2,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a349caf1-c498-40a6-a1d3-e99fbb406818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [12:47<00:00,  2.65it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method tqdm.close of <tqdm.std.tqdm object at 0x7f8f3437ba60>>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2000\n",
    "\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(total = epochs, position=0, leave=True)\n",
    "for epoch in range(epochs):\n",
    "    losses.append(train_one_epoch(model, loader, optimizer, loss_fn))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7041afdc-ab56-42bd-ac05-b186d72db448",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optim_GCN_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb2e2450-a88e-4e59-974c-fbff10930b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8f3065beb0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYNUlEQVR4nO3de3RV5ZnH8e9DiCRqhCrQlgQkKFBFIWi8dNCWlo6g7VJqZwrYeqG6LLWgrUumoNZBO1hbxstyacfGqm3HClqlaO2Ftio6tUoNF0GEKGKUAC0BBVGDuT3zx9mBk3BOckLOJXvn91krK+e8e5/9vCeEX/Z5997vNndHRETCr1euOyAiIumhQBcRiQgFuohIRCjQRUQiQoEuIhIRvXNVuH///j506NBclRcRCaUVK1bscPcBiZblLNCHDh1KZWVlrsqLiISSmb2VbJmGXEREIkKBLiISEQp0EZGIyNkYuohIMg0NDdTU1LB3795cdyVnCgoKKCkpIT8/P+XXKNBFpNupqamhqKiIoUOHYma57k7WuTs7d+6kpqaG0tLSlF+nIRcR6Xb27t3LUUcd1SPDHMDMOOqoozr9CUWBLiLdUk8N8xYH8/4V6CIiEaFAFxFJ4je/+Q1mxoYNGwCorq6msLCQsWPHctxxx3Hqqafyi1/84oDXjRkzhmnTprVqu+SSSzj00EPZs2fPvrarrroKM2PHjh1p6a8CXUQkiYULF3LGGWewaNGifW3HHHMMq1atYv369SxatIjbb7+dBx54YN/y9evX09zczHPPPccHH3zQanvHHnssjz/+OADNzc0888wzFBcXp62/CnQRCb0lq7Yw7panKZ3zO8bd8jRLVm3p8jbff/99nn/+ee67775WgR5v2LBh3Hbbbdx555372h566CEuvPBCzjrrLJ544olW60+bNo2HH34YgGXLljFu3Dh6907fyYYKdBEJtSWrtjB38Vq27KrDgS276pi7eG2XQ33JkiVMmjSJESNGcOSRR7Jy5cqE65100kn7hmQAHn74YaZMmcK0adNYuHBhq3WHDx9ObW0t7777LgsXLmTq1Kld6mNbCnQRCbUFS6uoa2hq1VbX0MSCpVVd2m584E6dOvWAcG4Rf1/ml156iQEDBnD00UczYcIEVq5cybvvvttq/fPPP59FixaxfPlyzjzzzC71sS1dWCQiobZ1V12n2lOxc+dOnn76aV555RXMjKamJsyMK6644oB1V61axXHHHQfE/ghs2LCBlqnB33vvPR577DEuu+yyfetPnTqVk046iYsvvphevdK7T609dBEJtUH9CjvVnopHH32Uiy66iLfeeovq6mo2b95MaWkpNTU1rdarrq7mmmuuYdasWTQ3N/PrX/+aNWvWUF1dTXV1NY8//vgBe/ZDhgxh/vz5Cf84dJX20EUk1GZPHMncxWtbDbsU5ucxe+LIg97mwoULmTNnTqu2r3zlK9x888288cYbjB07lr1791JUVMSsWbOYPn06y5Yto7i4uNVZK5/5zGd49dVX2bZtW6ttffOb3zzovrXH4sd/sqm8vNx1gwsRSWT9+vX7hjFSsWTVFhYsrWLrrjoG9Stk9sSRTB6bvtMBcyXRz8HMVrh7eaL1tYcuIqE3eWxxJAK8qzSGLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxFJYv78+YwaNYrRo0dTVlbG8uXLaWxs5Nprr2X48OGUlZVRVlbG/Pnz970mLy+PsrIyRo0axZgxY7jttttobm7OSn912qKISAIvvPACTz75JCtXrqRPnz7s2LGD+vp6rr/+ev7xj3+wdu1aCgoK2LNnD7feeuu+1xUWFrJ69WoAtm/fzgUXXMDu3bu58cYbM95nBbqIhN+aR+Cpm2B3DfQtgQk3wOivdmmT27Zto3///vTp0weA/v378+GHH3LvvfdSXV1NQUEBAEVFRcybNy/hNgYOHEhFRQWnnHIK8+bNy/ht9TTkIiLhtuYR+O2VsHsz4LHvv70y1t4FZ511Fps3b2bEiBFcccUVPPvss2zcuJEhQ4ZQVFSU8naGDRtGc3Mz27dv71J/UqFAF5Fwe+omaGgzs2JDXay9Cw4//HBWrFhBRUUFAwYMYMqUKSxbtqzVOg888ABlZWUMHjyYzZs3J91WtqZY0ZCLiITb7prOtXdCXl4e48ePZ/z48Zx44on89Kc/5e2332bPnj0UFRUxffp0pk+fzgknnEBTU1PCbWzatIm8vDwGDhzY5f50RHvoIhJufUs6156iqqoqXn/99X3PV69ezciRI7n00kuZOXMme/fuBaCpqYn6+vqE26itrWXGjBnMnDkz4+PnoD10EQm7CTfExszjh13yC2PtXfD+++8za9Ysdu3aRe/evTn22GOpqKigb9++fP/73+eEE06gqKiIwsJCLr74YgYNGgRAXV0dZWVlNDQ00Lt3by688EKuvvrqLvUlVZo+V0S6nc5On5uJs1y6A02fKyI9z+ivRiLAu0pj6CIiEaFAF5FuKVfDwd3Fwbx/BbqIdDsFBQXs3Lmzx4a6u7Nz5859V6OmSmPoItLtlJSUUFNTQ21tba67kjMFBQWUlHTu1EsFuoh0O/n5+ZSWlua6G6GjIRcRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEZFSoJvZJDOrMrONZjYnwfK+ZvZbM3vZzNaZ2fT0d1VERNrTYaCbWR5wN3A2cDwwzcyOb7Pat4FX3X0MMB641cwOSXNfRUSkHansoZ8KbHT3Te5eDywCzmuzjgNFZmbA4cA7QGNaeyoiIu1KJdCLgc1xz2uCtnh3AccBW4G1wFXu3tx2Q2Z2uZlVmlllT564XkQkE1IJdEvQ1va+UBOB1cAgoAy4y8yOOOBF7hXuXu7u5QMGDOhkV0VEpD2pBHoNMDjueQmxPfF404HFHrMReBP4VHq6KCIiqUgl0F8ChptZaXCgcyrwRJt13gYmAJjZx4GRwKZ0dlRERNrX4T1F3b3RzGYCS4E84H53X2dmM4Ll9wA/AH5uZmuJDdF8z913ZLDfIiLSRko3iXb33wO/b9N2T9zjrcBZ6e2aiIh0hq4UFRGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiOid6w501pJVW1iwtIqtu+oY1K+Q2RNHMnlsca67JSKSc6EK9CWrtjB38VrqGpoA2LKrjrmL1wIo1EWkxwvVkMuCpVX7wrxFXUMTC5ZW5ahHIiLdR6gCfeuuuk61i4j0JKEK9EH9CjvVLiLSk4Qq0GdPHElhfl6rtsL8PGZPHJmjHomIdB+hOijacuBTZ7mIiBwoVIEOsVBXgIuIHChUQy4iIpJc6PbQdWGRiEhioQp0XVgkIpJcqIZcdGGRiEhyoQp0XVgkIpJcqAJdFxaJiCQXqkD/3KcGdKpdRKQnCVWgP7OhtlPtIiI9SUqBbmaTzKzKzDaa2Zwk64w3s9Vmts7Mnk1vN2M0hi4iklyHgW5mecDdwNnA8cA0Mzu+zTr9gJ8A57r7KODf099VjaGLiLQnlT30U4GN7r7J3euBRcB5bda5AFjs7m8DuPv29HYzRpNziYgkl0qgFwOb457XBG3xRgAfM7NlZrbCzC5KtCEzu9zMKs2ssra28+Pek8cW88PzT6S4XyEGFPcr5Ifnn6iLikRESO1KUUvQ5gm2czIwASgEXjCzF939tVYvcq8AKgDKy8vbbiMlmpxLRCSxVAK9Bhgc97wE2JpgnR3u/gHwgZk9B4wBXkNERLIilSGXl4DhZlZqZocAU4En2qzzOHCmmfU2s0OB04D16e2qiIi0p8M9dHdvNLOZwFIgD7jf3deZ2Yxg+T3uvt7M/gisAZqBn7n7K5nsuIiItGbuBzWU3WXl5eVeWVmZk9oiImFlZivcvTzRslBdKSoiIsmFaj500A0uRESSCVWg6wYXIiLJhWrIRTe4EBFJLlSBrsm5RESSC1Wga3IuEZHkQhXompxLRCS5UB0UbTnwqbNcREQOFKpAB03OJSKSTOgCXeehi4gkFqpA13noIiLJheqgqM5DFxFJLlSBrvPQRUSSC1Wg6zx0EZHkQhXosyeOJL9X6zvi5fcynYcuIkLIAh048A6nie54KiLSA4Uq0BcsraKhqfUNORqaXAdFRUQIWaDroKiISHKhCnQdFBURSS5Uga7JuUREkgvVlaKanEtEJLlQBTpoci4RkWRCNeQiIiLJKdBFRCJCgS4iEhEKdBGRiAjdQVHQTS5ERBIJXaDrJhciIomFbshFN7kQEUksdIGu+VxERBILXaBrPhcRkcRCF+iaz0VEJLHQHRTVfC4iIomFLtBB87mIiCQSuiEXERFJTIEuIhIRoRxy0ZWiIiIHCl2g60pREZHEQjfkoitFRUQSC12g60pREZHEQhfoulJURCSx0AW6rhQVEUksdAdFdaWoiEhioQt00JWiIiKJhG7IRUREEksp0M1skplVmdlGM5vTznqnmFmTmf1b+rp4oCWrtjDulqcpnfM7xt3yNEtWbclkORGRUOhwyMXM8oC7gX8FaoCXzOwJd381wXo/ApZmoqMtdGGRiEhiqeyhnwpsdPdN7l4PLALOS7DeLOAxYHsa+9famkc4/fHPsq7XFP56yJWc2+uvgC4sEhGB1AK9GNgc97wmaNvHzIqBLwP3tLchM7vczCrNrLK2trZzPV3zCPz2Sj5BLb0MSnrt4I78n3Bj7/sBXVgkIpJKoFuCNm/z/A7ge+7elGDd/S9yr3D3cncvHzBgQIpdDDx1EzS0Du1eBhfm/YVze/1VFxaJSI+XymmLNcDguOclwNY265QDi8wMoD9wjpk1uvuSdHQSgN01CZt7Gdycfx9/mTgzbaVERMIolUB/CRhuZqXAFmAqcEH8Cu5e2vLYzH4OPJnWMAfoWwK7NydcdJh9pAOiItLjdTjk4u6NwExiZ6+sBx5x93VmNsPMZmS6g/tMuCFrpUREwsjc2w6HZ0d5eblXVlZ27kXz+iZsdoe6PgM59NrX09AzEZHuy8xWuHt5omWRuFLUDArrt8Ndp+W6KyIiOROyQE90wk3ckh0bYnvxCnYR6YHCNTlX+TfwyvvaifVAS7AnZXB+BYz+aho7JyKSW+EaQwd8Xt+OA11EJAzKL4Uv3dapl0RqDH37UaeTo79BIiLpVXkfPHl12jYXukA//4Pv8ZH3UqiLSDSs+HnaNhW6QN+6q45P1T9Ig6NQF5Hwa3/GlE4JXaC3zNkyov4hNngxrmAXkTCzvI7XSVHoAv1zn9o/qdfZ9Qso/eghftn0BZpz2CcRkYN28iVp21S4TlsEntlw4LS7/9n4DSoO/zbPz/l88hf+cAh8tDuDPRMR6aSDOMulPaEL9GTznm/paD70uW9noDciIt1H6IZc+h2an7DdQPcWFZEeLVSBvmTVFt7f25hwmYNuQyciPVqoAn3B0ioampOf0qLb0IlITxaqQO8osPsWJh6OERHpCUIV6B3dN7S+MX0n6IuIhE2oAn32xJEU5ic/Cf/DBp2NLiI9V6hOW2y5b+h3Hl6d246IiHRDodpDBzq8GfTQOb/LUk9ERLqX0AV6Ko6dq1AXkZ4nkoHe6HDa/D/nuhsiIlkVykA/7JCOZyf75556vnbvC1nojYhI9xDKQJ//5RNTWu/5N95RqItIjxHKQJ88tpg7ppSltO7zb7xDqQ6UikgPEKrTFuNNHltM5Vvv8OCLHc+i6Ow/+8WA26eUdXi2jIhI2Jjn6HY/5eXlXllZ2eXtnDb/z/xzT30aepRcQZ6xYf45Ga0hIpIKM1vh7uUJl4U90CF2mmKjbkMnIiHz9dOH8F+TUzsm2KK9QA/lGHpbG3/4xVx3QUSk0x588W2uX7I2bduLRKADVN+iUBeR8Fm4fHPathWZQIdYqA8feFiuuyEikrKmNA57RyrQAf589Xiqb/kiR/Tp+OIjEZFcyzNL27ZCe9piR9bcOGnf49H/+Ufe+0hzpYtI9zPttMFp21ZkAz1efLinSn8ERCTTDuYsl/b0iEA/GAfzR0BEJJciN4YuItJTKdBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhIKdDNbJKZVZnZRjObk2D518xsTfD1NzMbk/6uiohIezoMdDPLA+4GzgaOB6aZ2fFtVnsT+Ky7jwZ+AFSku6MiItK+VPbQTwU2uvsmd68HFgHnxa/g7n9z93eDpy8CJentpoiIdCSV+dCLgfi7mNYAp7Wz/qXAHxItMLPLgcuDp++bWVUqnUygP7DjIF/bVbmqrffcM2rrPUe/blcdnWxBKoGe6IZ3Ce9qamafIxboZyRa7u4VpGE4xswq3b28q9sJU229555RW+85+nUzKZVArwHib3pXAmxtu5KZjQZ+Bpzt7jvT0z0REUlVKmPoLwHDzazUzA4BpgJPxK9gZkOAxcCF7v5a+rspIiId6XAP3d0bzWwmsBTIA+5393VmNiNYfg9wA3AU8BMzA2jM8EeZXJ5Fk6vaes89o7bec/TrZoy5JxwOFxGRkNGVoiIiEaFAFxGJiNAFekfTEHRx24PN7BkzW29m68zsqqD9SDP7s5m9Hnz/WNxr5gZ9qTKziV2sn2dmq8zsySzX7Wdmj5rZhuC9fzobtc3su8HP+RUzW2hmBZmqa2b3m9l2M3slrq3TtczsZDNbGyy704KDRgdRe0Hw815jZr8xs37prp2obtyya8zMzax/tuqa2axg2+vM7MfprpustpmVmdmLZrbazCrN7NRM1O4W3D00X8QOyr4BDAMOAV4Gjk/j9j8JnBQ8LgJeIzbdwY+BOUH7HOBHwePjgz70AUqDvuV1of7VwEPAk8HzbNX9BXBZ8PgQoF+maxO7YO1NoDB4/ghwSabqAp8BTgJeiWvrdC3g78CniV2f8Qdip+keTO2zgN7B4x9lonaiukH7YGInObwF9M9GXeBzwF+APsHzgVn8Wf+p5bXAOcCyTNTuDl9h20PvcBqCrnD3be6+Mni8B1hPLHjOIxZ6BN8nB4/PAxa5+0fu/iawMehjp5lZCfBFYufyt8hG3SOI/Se4D8Dd6919VzZqEzvLqtDMegOHEru+ISN13f054J02zZ2qZWafBI5w9xc89r/+l3Gv6VRtd/+TuzcGT+Ony0hb7STvGeB24D9ofYFgput+C7jF3T8K1tme7rrt1HbgiOBxX/ZfR5PW2t1B2AI90TQExZkoZGZDgbHAcuDj7r4NYqEPDMxAf+4g9p+sOa4tG3WHAbXAAxYb7vmZmR2W6druvgX4b+BtYBuw293/lOm6bXS2VnHwOJ19APgG+6fLyGhtMzsX2OLuL7dZlOn3PAI408yWm9mzZnZKluoCfAdYYGabif3Ozc1i7awKW6CnPA1Bl4qYHQ48BnzH3d/LdH/M7EvAdndfkepL0lE30JvYR9T/cfexwAfEhh8yWjsYrz6P2EfdQcBhZvb1TNdNUbJaae+DmV0HNAK/ynRtMzsUuI7YdSMHLM5U3UBv4GPA6cBs4JFgXDobP+tvAd9198HAdwk+jWapdlaFLdBTmoagK8wsn1iY/8rdFwfN/ww+hhF8b/m4mK7+jAPONbNqYsNInzezB7NQt2VbNe6+PHj+KLGAz3TtLwBvunutuzcQu9L4X7JQN15na9XQeibRLvXBzC4GvgR8Lfhon+naxxD7A/py8LtWAqw0s09kuC7BdhZ7zN+JfRLtn4W6ABcT+/0C+DX7h+qy8u+cVbkexO/MF7G/8puI/VK2HBQdlcbtG7HxsjvatC+g9cGzHwePR9H6oMomunBwMtjmePYfFM1KXeD/gJHB43lB3YzWJjZj5zpiY+dGbAx7VibrAkNpfbCs07WITYVxOvsPlp1zkLUnAa8CA9qsl9babeu2WVbN/oOiGa0LzABuCh6PIDbUYVn6Wa8HxgePJwArMvXvnOuvnHeg0x2OHaV+jdgR6evSvO0ziH20WgOsDr7OITatwVPA68H3I+Nec13QlyrScCSc1oGelbpAGVAZvO8lxD4aZ7w2cCOwAXgF+N/gP1ZG6gILiY3VNxDbA7v0YGoB5UF/3wDuIrja+iBqbyQWai2/Z/eku3aium2WVxMEeqbrEtsBezDYzkrg81n8WZ8BrCAW3suBkzNRuzt86dJ/EZGICNsYuoiIJKFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hExP8DjMHyq1x+pOcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(sgd_optim_GCN_losses)\n",
    "adam_y = [item.detach().numpy() for item in adam_optim_GCN_losses]\n",
    "sgd_y = [item.detach().numpy() for item in sgd_optim_GCN_losses]\n",
    "\n",
    "\n",
    "plt.scatter(range(epochs), adam_y, label='ADAM')\n",
    "plt.scatter(range(epochs), sgd_y, label='SGD')\n",
    "\n",
    "plt.yticks(np.arange(start=0, stop=1, step=0.2))\n",
    "plt.xticks(np.arange(start=0, stop=2000, step=200))\n",
    "plt.ylim(0.2, 1.0)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df8da6e-c11e-441c-b403-1331be96969a",
   "metadata": {},
   "source": [
    "### EdgeConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28243742-a0f8-4bf0-9384-20ea899eb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num model params: 16\n"
     ]
    }
   ],
   "source": [
    "model = EdgeConv(2,2)\n",
    "print('num model params:', count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70fb298b-8b8a-41f6-9c73-8378a743173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([818, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data_loader, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m model_out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat(), batch\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/functional.py:3261\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3259\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3261\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/functional.py:75\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch(model, loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c596e577-9a7d-46b2-a957-12eaa1a7a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab3c9dc4-90d8-4e64-91b9-60624ad60f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Softmax(dim=1)\n",
    "inp = torch.randn(2, 3)\n",
    "output = m(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0b4121b-8fd1-4dbf-a21a-9882229024c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6567, 0.1431, 0.2002],\n",
       "        [0.1342, 0.6416, 0.2242]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9e18af7-dc2c-4378-a3a9-264bed626874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2658, -1.2583, -0.9221],\n",
       "        [ 0.8187,  2.3836,  1.3323]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86cbac-d010-42b6-8d72-9de82e7e4dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
