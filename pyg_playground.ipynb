{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1ce11e47-318b-4293-9c96-d4bda137baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tgn\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09bfa4-93d4-455b-b2ce-56061024d0dd",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e26da9f2-a970-4c08-9f8e-48e6c870e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(30, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c465aa0-7fde-4b4a-a1e6-c2492b8612ae",
   "metadata": {},
   "source": [
    "# Training and Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "835d60e2-6926-4a3f-a974-168da5bf72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer, loss_fn):\n",
    "    \n",
    "    for _, batch in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        model_out = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "        # loss = loss_fn(torch.squeeze(model_out), batch.y.float())\n",
    "        loss = loss_fn(model_out, batch.y)\n",
    "\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f99e97a4-66b6-4ce8-93ec-8383c0f2cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3b38fa63-52ff-48b8-9b6c-b9c2a6307638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x.float(), data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f36fa-7bc9-4f00-8f61-b794918b554d",
   "metadata": {},
   "source": [
    "# Message Passing Pyg Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de23dd-5916-438a-be14-a44637340aad",
   "metadata": {},
   "source": [
    "### Rich Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a530fc1c-faef-42b7-ac6e-dd833af0eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d22e08a4-3d00-4165-96a2-2f8d995c7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_data = torch.load('rich_dataset.pt') # 30 node features, 11 edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7a758d9a-71b8-4036-9f9a-7d22f553b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rich_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2efef0c1-0d00-4b84-8524-09a9cf623515",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(rich_data[:int(len(rich_data)*0.9)], batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(rich_data[:int(len(rich_data)*0.9)], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267fa24-03ab-468b-9d5c-3d6309bc1bb1",
   "metadata": {},
   "source": [
    "### Simple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bbeff239-2f3b-48e6-9be5-d85ec1856d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = torch.load('tensor_list.pt')\n",
    "\n",
    "data_list = torch.load('tensor_list_node_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "973f50e7-c083-40f2-8170-871700e50bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list[:int(len(data_list)*0.9)], batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(data_list[:int(len(data_list)*0.9)], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce6e90-1dd1-46b4-a2b8-327a53a7080d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e2e21aff-12f6-4829-88d0-873ee889cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "# *** NOTE on loss function *** I think Cross Entropy Loss requires a different output channel for each class ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a349caf1-c498-40a6-a1d3-e99fbb406818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 500/500 [23:44<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "test_scores = []\n",
    "pbar = tqdm(total = epochs, position=0, leave=True)\n",
    "for epoch in range(epochs):\n",
    "    losses.append(train_one_epoch(model, train_loader, optimizer, loss_fn))\n",
    "    test_scores.append(test(test_loader))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7041afdc-ab56-42bd-ac05-b186d72db448",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "893c1110-ad0b-4b07-bee7-d4d32bdd363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/maxperozek/CP341/Proj/CP341_B722_GNN/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4756fd8c-575a-4c3f-96eb-8e6db93659ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path+'GNN_1_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "eb2e2450-a88e-4e59-974c-fbff10930b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8ef6d2c520>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8SElEQVR4nO2df5BdVZXvv6s7N+QmIA0YKe2kSbSYBGIkLT0QKlM8g28IiEIP/oiAJVpjUdQTZ+AxcWKNJWEeDGFSPpipYeTxHEun4JmgaE8Q3ouOib8nSmInQEviRH52ByESmnFIh3S69/vj3t19+tz985x97j3n3PWpSqX73tPn7HPO3muvvfb6QUIIMAzDMMWno9UNYBiGYcLAAp1hGKYksEBnGIYpCSzQGYZhSgILdIZhmJIwq1UXfvOb3ywWLVrUqsszDMMUkt27d/9OCDFf9V3LBPqiRYuwa9euVl2eYRimkBDRc7rvrCYXIvoKEb1MRE9qvici+nsiOkBEjxPRu9M0lmEYhkmGiw39qwAuMXx/KYAz6/+uA/Cl9M1iGIZhfLEKdCHEjwAcNhxyBYB/FjV2AugioreGaiDDMAzjRggbejeAFyK/D9c/ezHAuRmGYRoYHx/H8PAwjh492uqmZMacOXOwYMECVCoV578JIdBJ8ZkyQQwRXYeaWQY9PT0BLs0wTDsyPDyMk046CYsWLQKRSgQVGyEEXnnlFQwPD2Px4sXOfxfCD30YwMLI7wsAHFQdKIS4TwjRJ4Tomz9f6XXDNImBwRGs2rgdi9c/glUbt2NgcKTVTWIYZ44ePYrTTjutlMIcAIgIp512mvcKJIRA3wrg43Vvl5UAXhNCsLklxwwMjuBz33oCI6NjEABGRsfwuW89wUKdKRRlFeaSJPfn4rb4dQD/BmAJEQ0T0Z8S0fVEdH39kEcBPA3gAID/DeC/ebeCaSqbtu3H2PjEjM/Gxiewadv+FrWIYZgQuHi5XCWEeKsQoiKEWCCE+CchxL1CiHvr3wshxKeFEO8QQiwXQnC0UM45ODrm9TnDMI289NJLuPrqq/H2t78d5557Li644AJ8+9vfBgD84he/wIUXXoglS5Zg6dKl+NSnPoUjR47gq1/9Kjo6OvD4449Pneed73wnnn322SBt4lwubcjbuqpenzMMMxMhBPr7+3HhhRfi6aefxu7du7F582YMDw/jpZdewoc//GHceeed2L9/P5566ilccskl+P3vfw8AWLBgAW6//fZM2sUCvQ1Zt2YJqpXOGZ9VK51Yt2ZJi1rEMNkS2glg+/btmD17Nq6//vqpz8444wx85jOfwT333INrr70WF1xwAYCaLfxDH/oQTj/9dADA+9//fgwNDWH//vAmThbobUh/bzfuuHI5uruqIADdXVXcceVy9Pd2t7ppDBOcLJwAhoaG8O53q7OcPPnkkzj33HO1f9vR0YHPfvaz+Ju/+ZvE19fRsuRcTGvp7+1mAc60BSYngFBj4NOf/jR+8pOfYPbs2Vi4cKH1+Kuvvhq33347nnnmmSDXl7CGzjBMqcnCCWDZsmX45S9/OfX7Pffcg+9///s4dOgQli1bht27dxv/ftasWbj55ptx5513Jm6DChboDMOUmiycAC666CIcPXoUX/rSdC7CI0eOAABuuOEGfO1rX8PPf/7zqe/uv/9+/Pa3v51xjk984hP413/9Vxw6dChxO+KwQGcYptRk4QRARBgYGMAPf/hDLF68GOeddx6uvfZa3HnnnTj99NOxefNm/MVf/AWWLFmCs846Cz/+8Y/xpje9acY5Zs+ejT/7sz/Dyy+/nLgdDe0SQpl2JXP6+voEF7hgGCYJTz31FM466yzn4wcGR7Bp234cHB3D27qqWLdmSSH2kFT3SUS7hRB9quN5U5RhmNLTLk4AbHJhGIYpCSzQGYYpJK0yFzeLJPfHJhdPimqLY5gyMWfOHLzyyiulTaEr86HPmTPH6+9YoHsgI85kkIKMOAPAQp1hmsiCBQswPDwc1OUvb8iKRT6wQPegGRFnDMPYqVQqXpV82gW2oXvAaWcZhskzLNA94LSzDMPkGRboHnDaWYZh8gzb0D2QdnL2cmEYJo+wQPekXSLOGIYpHmxyYRiGKQks0BmGYUoCC3SGYZiSwAKdYRimJLBAZxiGKQks0BmGYUoCC3SGYZiSwAKdYRimJLBAZxiGKQks0BmGYUoCh/4zDJMLuBpYeligM0wgWCAlh6uBhYFNLgwTACmQRkbHIDAtkAYGR1rdtEJgqgbGuOMk0InoEiLaT0QHiGi94vuTiehhItpLRENE9MnwTWWY/MICKR1cDSwMVoFORJ0A7gFwKYCzAVxFRGfHDvs0gF8JIc4B8B4AXySi2YHbyjC5hQVSOrgaWBhcNPTzABwQQjwthDgGYDOAK2LHCAAnEREBOBHAYQDHg7aUYXIMC6R0cDWwMLgI9G4AL0R+H65/FuUfAJwF4CCAJwD8uRBiMkgLGaYAsEBKR39vN+64cjm6u6ogAN1dVdxx5XLeEPXExcuFFJ+J2O9rAOwBcBGAdwD4HhH9WAjxHzNORHQdgOsAoKenx7uxDJNXuDxhergaWHpcBPowgIWR3xegpolH+SSAjUIIAeAAET0DYCmAX0QPEkLcB+A+AOjr64tPCgxTaFggMa3GxeTyGIAziWhxfaPzowC2xo55HsB7AYCITgewBMDTIRvKMAzDmLFq6EKI40R0A4BtADoBfEUIMURE19e/vxfA/wDwVSJ6AjUTzV8KIX6XYbsZhmGYGE6RokKIRwE8Gvvs3sjPBwFcHLZpDMPkDY6GzTcc+s8wjBMcnp9/OPSfYRgnOBo2/7BAZxjGCY6GzT8s0BmGcYKjYfMPC3SGYZzgaNj8w5uiTFvC3hr+cDRs/mGBzrQd7K2RHI6GzTcs0FPAWl4xMXlr8PtjigwL9ISwlldc2FuDKSu8KZoQ9snNNwODI1i1cTsWr38EqzZun1EKjr01mLLCAj0hrOXlF1t9T/bWYMoKC/SEsJaXX2yrJy6mwJQVtqEnZN2aJTNs6ABreXnBZfXE3hpMGWENPSGs5eUXXj0x7Qpr6ClgLS+f8OqJaVdYoDOlgyMa2w+OCanBAp0pJbx6ah84JmSaUgh0np0Zpn3hyN9pCi/QeXZmmPaGY0KmKbyXC0dsNg9T9CXDtAr2apqm8AKdZ+fmYIu+ZJhWwZG/0xReoPPs3Bx4JcTkFY4JmabwNnT2OW4OvBJi8gx7NdUovIbOs3Nz4JUQw+SfwmvoAM/OzYBXQgyTf0oh0Jns4ehLhsk/LNALTLMDqnglxDD5hgV6QeGAKoZh4rBALwhxbfzIseMc7swwzAxKI9DLnM9FpY3rYDdCN8rcX5j2pRQCvezmB1VQjw52I7RT9v7SDHhCzCeF90MHyh/F6Kp1sxuhG2XvL1nDaSDyi5NAJ6JLiGg/ER0govWaY95DRHuIaIiIfhi2mWbKHsWo07q7qhUOqEpA2ftL1vCEmF+sJhci6gRwD4A/BjAM4DEi2iqE+FXkmC4A/wjgEiHE80T0lozaq+RtXVWlXbks5gddUM+Gy5exAE9A2ftL1vCEmF9cNPTzABwQQjwthDgGYDOAK2LHXA3gW0KI5wFACPFy2GaaKXu2NU5vEJay95es4TQQ+cVlU7QbwAuR34cBnB875g8AVIjoBwBOAvB3Qoh/jp+IiK4DcB0A9PT0JGmvknaIYuSgnnC0Q3/JEk4DkV9cBDopPhOK85wL4L0AqgD+jYh2CiF+PeOPhLgPwH0A0NfXFz9HKsoo8NiTIDvK2F+aRZEmxHYbQy4CfRjAwsjvCwAcVBzzOyHE6wBeJ6IfATgHwK/BJIJd65g8U4QJsR3HkItAfwzAmUS0GMAIgI+iZjOP8i8A/oGIZgGYjZpJ5q6QDU1DEWfpohe+jT/z1UvnY8e+Q4V6B0yxKfoYSoJVoAshjhPRDQC2AegE8BUhxBARXV///l4hxFNE9P8APA5gEsCXhRBPhm5sEsFc1Fm6yJ4Eqmd+/87np74vyjsoKkVUYLKgyGMoKU5+6EKIR4UQfyCEeIcQ4vb6Z/cKIe6NHLNJCHG2EOKdQoi7Qzc0aTBDUX1mi+xJ4BLZWoR3UEQ46GeaIo+hpBQmUtQmmHUV6Zs1S+uun5Qiu9a5Ptsya0qtoqgKTJRQY6nIYygphcnlYhLMJrNKM4JIsjDrFMmTII7umauOY8JSdDNDyLFU5DGUlMIIdJNgNmklzfCZzWrzpQieBCpUzzxO2TWlVlH0KNjQY6moYygphTG5mJZPJq2kGVGWRdeKQqN65h9b2cORrk2g6GYGHkvpKIyGblo+bdq236iVZD1LF10ryoL4+9qx71Dpl7t5oOhmBh5L6SiMQAf0grnVocitvn4eKaq7aBkospmBx1I6CiXQdbRaK2n19fOIzhZ684N7AbRWqLOfdn7hsZQOEiJoShVn+vr6xK5du1pybSZ7Fq9/pCHhj6Ra6WyZDT2+cmh1exjGFyLaLYToU31XmE3RpITwaQ3tY94OmGyerfSLLoOfNsPoKLVADxE1x5F3yVB5W0RJ67WQdJJlLwqmzJRaoLtoYzbBwBpdMqTrYiepsi+n81pIM8m2Yzg40z6UWqDbtDEXwaA7x0g9QpXR09/bjS9+5JzgftFpJtmi+2mz+Y8xUQovFx02n1aXqDRTGHtSN7wieFmEamMWXgtpzCZF9qJgV1DGRqkFus2n1UUwmMLYk4QkF2FQpmmjbiIIeW9pg0+a7acdanJsx/zejB+lNrnYwv5d7KnyHDp8N9OKYJO/9eGhRG1s1gZykcwmIZ8Jb+gyNkqtoQNmbcw1Ks0lvYArLoOylSaZgcERvHpk3NpGFc3SIItkNgn5TEKHxRfB9Mf4UWoN3YZP4q5QWqFtVdBqN0mTFm4THL4aZJoNvv7ebvx0/UW4a+0KAMBNW/ZkukmYBzfJkCuTVvczJhtKr6HbcLWnhtIKbauCVttJTYLGJjh8NMgQewnN2o9Ic52QWnXIlUmr+1kcXi2Eoe0Fug8hNtNsg7LVdlKdAOqqVqz37pNYKYRAaZZQSnOd0MmmQm3otrqfRSmCo0BRYIHeAkyDUidQT65Wsm4WAL0A2nD5Muvf+miQIQRKs4RSGd0kQ6wcsvbeuXHLnqkiNarzslbfCAv0nCA7p87n/fVjxzEwOJJ5h00rgFw1yBACpVm5s4vmJulC2pVDSK3aNDHqzps3rT4vk0vhNkXLGCkX3aDSMT4hmubaKDccn9l4GX66/qJMOmaIDb5muS8WyU3SlbSVvEK639omRtV58+T+m6cN5kJp6Elm5bzMnCZUnVNFmfyNQ5gisjRnxPvNB8/txo59h3Ldj3xJs3II7b1jq0EbP2+e9gDytMFcKIHu++DytizT4doJy5ZAKtQmc+h3qeo3D+0e4ZzpEbLy3tGtUuPnzVOpujxNLoUyufg+ONMEkCfTjUsnLPoSX0ee3oOkFcv5PD4HE6HNUNLMd/faFU7nzZMZLE8ZPAulofvOyqZMiXnR3AcGR/D6G8eNx3SXZIkfJw8rKJVJrtkaVx6egy9Zmbvk32/YOoTRsVrE8pxKo96ZJ++hPNVBLZRAVz04ArB66Xzl8boJoJPI2XSTpQ1eVQ4tTndXFT9df1GQ6+WNVtsedYK0a25Fmf4gK42r1c8hKVl677xxfHLq51ePjCsnuLx4D+VpcimUQO/v7cau5w7jgZ3PT9WrFAAe2j2CvjNObXiAuplTJ0DjGljWmpPLZmiZNkLjtNr2qBOkJ8zqaOgnWWhcNlfVMr97E62c4JIqcHmZXAplQweAHfsONRQfltXk43ZHnWtWt4PNa2BwBDc/uDdTW6rLgC3bRmiUVtsedc//tbHxVC59Lri4qpb53ZswmUqzJE/uh0kplIYO6F/2hBBeyzKTzUu+2AmhrlsfSnMyFc+It6mMtNr2aNqTyVrjsq3Oyv7uTejeCwGZBtcV1fQVpXAaeohq8ragCttgC6U5qXbqZQXOLLTCvJE2uCUtrfSUMCkF7fDuTaxbswSqSrQCwI0ZZtXM0vTVLC+mwmnotiAE14dv0sBM5wg54PO0mdIqWml7bOXz12mhZd4Ed6W/txs3btmj/T4LL6CBwREQ0GDOBdIrcM30YnIS6ER0CYC/A9AJ4MtCiI2a4/4QwE4Aa4UQ3wzWygjyAdz84F6lSSSE9mzyjkmrOak2Xdp9ALeSVk0orTY35Z1uizkytClk07b9SmFOsKeNdjl3s0w5VpMLEXUCuAfApQDOBnAVEZ2tOe5OANuCtlBBf2821eQluqX4Fz9yTmphXvRNFyYMrTY3qchTcJNqDMYJ6QWkO5dAei26md5cLhr6eQAOCCGeBgAi2gzgCgC/ih33GQAPAfjDoC3UYFsup/Efz2opnsVMXYRcNYyavLi6AfkLbkqSDiCOz9gwmcDS0sy4BheB3g3ghcjvwwDOjx5ARN0A/gTARTAIdCK6DsB1ANDT0+Pb1gZ0AyJE5ww12KKdSu0z4zdTR893crWC148dx/hE7cytHoR5Iu8TXd7al0cPDzkGVQF4ttW4rwzIygQ2MDiC/zzaGAle6aRMzGsuAl234RzlbgB/KYSYIFIdXv8jIe4DcB8A9PX16eRbapJ2zjSDTPW3QKN7pArXmTreSWVodBTVfeZNeGRNM7TNtH0lT9ow0PwgL5/nl2TF7CsDslyVj082irp5s2dl8q5dBPowgIWR3xcAOBg7pg/A5rowfzOA9xHRcSHEQIhG+uLTOaPRetFdbp9BphugcyodVmHuM1MnSbPbzLqbrZ40TJGXIbXNtM80j9pwM7MXJnl+vivmJBNUFiYwU/BaFrgI9McAnElEiwGMAPgogKujBwghFsufieirAL7TKmEOmMu4rdq4fUrorF46Hw/tHpnqWKoIVJdBphugLsLXZ6ZOkma3GcIjDxqnS16cUNpm2mfa6pQHUXQKDZCd100z+mTWE5SrAtPsNL9WLxchxHEAN6DmvfIUgAeFEENEdD0RXZ9Jq1Kyeun8BjtRpYPw+rHjMzxMHtj5fJBcKmkGos9MnSTNrimMOpRHQx6qx7isXpIMIpXnRxqBPDA4gg6NWbLZof7x9AMCzQlsa8aElmXQmMpb7aYte/D5gSea2g4VTn7oQohHATwa++xezbGfSN8sM6bZcWBwBA/tHpmhaRCAjg6akcENUAcRxHEZZLpZuKtawRvHJ4NFna5bswQ3bdmjbbcqza4pjFp+nlajzoPGabtWkkEUOhujKaVEK3zQVZOgwHQ/2rRtP27asie4Ca0ZWmuWQWO65/bAzucbkgQ2O3itcJGituW97mHHhbkLroNMt0O+4fJlABBsSWuKoCNAGaCkSzmc1LykIvQATWKPN+XFSZpP3pSNsdJBMza7Kh32vRDdKiIasNbMvYhW1QtoVlCVq03c95mbfNZVY6iZ7qmFy+ViW96H1ApdlpyyM4yNT6CzvpSOLlf7e2uVWJ7deBnuWrsidSCJS6bIKKoAlhDuk1FCLiuTBl/p2nD32hWJC13rnsfo2Hij75feuct6vkkhZrjnNSvwTNdnTPUCQpCnoKokz9ykqLQ65XHhBLptee+rFc6brY5G665n3DMRt0FOCDElyHSuUT9dfxHuWrsCAHBTgkRDSYSnvO4zGy/DT9df5D0p2Ag5QJPa47MQEiaBJ33/JeMTwtpGW7rgZu9F6PpS1llGgcY+2SrvniTPXJc8DGh9yuPCmVxsy3tXEwNQs3FvuHxZoqAFk3vczQ/u1doe03qEhLDJZbHkDbWsTGOPD720TVsgxfV88rk3ey9C15d0fTuksMqDmyuQ3L0xXmgHyEcunsIJdNugUHXSuHui/JsNly9rOP7kagVENe1507b9VoGsQmo4KmEdwmUrqeCKR5nOqXRg9Mh4roKNktrjsxAQoQWebTJuRSV7XV/SjbEQzzkPbq6SpM/8tv7l6Dvj1FxMSlFIaJZXWdPX1yd27dqV6G+TdCqXv9GFGEeX7qs2bveunBJNibp4/SNaG/bda1dk1iFc7i0PJGlns+8tq+vl6R3Fx8vqpfPxnb0vNkQnJ2mfbgylTR2cVC7k5Zm7QkS7hRB9yu+KKNCzwqWjmQSyDgLwzMbLjNeQx12zsge39S/3vIKdEIOoWctk3+tkJSBCttH1XHKFaFs5NdNkYVuV+j5n3RiKjpMQbXQVzHkx/7hiEuiFM7mkxfTyXCqWmNzjOomsOdpNBToEgPt3Pg8AwYW6yUXNpaxXFstk3btoRph3WkLZ61X5eaqVTtxlWK0122RhC9ryfc5ZmJbSmDLjpjC5IZpnoa6jcF4uaTC5KMmKJSoEMOWNovIMqHQQTplbwYQQDeeIb5RIbwwTD+x8PrirmmmwuLjGhfbACOmi1+pi02lI8lyb7Q1jE9i+zzmNm6suZ3va6N2y1CloK4FuGgi6iiWSqBYUdY/rqlYAwlTkoEv4dH9vtzHPsgxQCImpYICLMAitBScRSrrBrKvNKtMb5Glgxu8hSR3LZq9ITAI7iWdHUhdTk+BNM6nnIXVFKNrK5JJ2IMiXLO2FOm8HGT5tsivawvhDDc64fTapy13oZbLvu3AxM6TNmpk1qntIUsey2d4wOjPhKXMruOUD055ivilxfd7HwOCIsuykHJNpXHHzkLoiFG2loZtmcdfBcLBuc44GFOmOM9Hf241rVuqLfIQYnHGNZnRsXGtWkpkodcm6fJfJtnJmvhqVTou6+cG9WLz+kalBrYqEzYu2pUtLYTPTxWl2wieVRn332hUY/MLFUxGuK279Lm7csicTs4UpBw5QG2tpAsuKbLKL01Yaum0Wdy1GkSazX1yLWfWOU/Gz3xx2ClDw3Y03CZDo9WQmSumSptJqfQKaXLRpX41KN0HGff6TrkCagSkHSHdX1fm9hk745NKvdBq1yQMmVEpc23iTYy3pRnWZCnYXVqAncTVyGQhR80S0vBsw/ZJv0iTIih+nanNc0B1+/RiuWdmDHfsOefnIu5gSXAXIkWPHG7IHqgajbcD4FJjwFUom76LoNVw8jbJG1zdNdSt93Suz8rIJUawjSoiJ1HSONILXFGi3eun8zLJNZkkhBXqaTqgaCPEBKF3GdANTJ7SA6cx+AGYU05ARhiqzwY59h6wDOolblqsAWbz+EeXf+wzGJAUmfISSyd0zisyn0ypty9Q3m6EJhljFhSjWIQkxker6cTRLpS8md1EAqSa5VlJIG7qpE9pst3F0yeoXReyy8QRCtsx+AJS78Uk8GmzHmDw5XG2tukHXQeT8HLMqMCFxcfcEpm2nrcrkZxOQSb07XPp0Eve7tBuCoT1gVOj68Rc/ck7i92rzeCuq10shNfSQeZx1dmbT39vMBboOkcYcYDI5JG2nRKf9mnLSxMmiwEQc2+oIqFWrCp2kywfbxBtfBdrwWY3aJhNVRKrOy8p18tX1nXmzO3H7n9Qm4PhK1ffdhN4zAJJNZHnYh7FRSIFuWoL5Lh9tL0n396ZNIp3ASWMOsJkc4u3UmZFUxAdMh2LiGRufwI2ahGWAvcCEi03SxVxgew479h1Sft4sQleI8jGJmISUysSgw2fy7e9VZx6cFMCu5w7PSIqXxnQRepK2uX4mdQtV5cCx7Y+FpJAml5B5nF1ekmv9TTlodKQxB0SX6zrkfSZZevf3TuennjTk99GdSxe4dMrcylS2S1N7XNtsM734Jk6L4muuU6ELcjK5Upqu66NJmtzvXExiQDIT1Y59h5T39/Wfv5C56UL17Fzeo8kcmdQtVNWH79/5fFMjUAubnEulzemW4yYvApfNPFXpOFWnN0X++WRwi3qLSDNNtIyaLRlV2mRVLhklVecaGBzBhq1DDdqfLnhGnkMXNGJqs66NBDibM+JtdwmecT1XtG+akrHdtXaFNqkUAO1z6STCpBAztD5TgipTEFu0PUmSY/kmrEuThCuK6n4rHQQQGrzTVGPPtCJMkjDNNRNr2qRxpUzOpVuC2bwIVC/xjiuXK6MMAb/6m6aVgI8wj96Dyo6ddaEEF48S1bmkjTsu0E3RsC5BI7o2qoSUrq6jDZ0G++qRcW8zQbxv6gb6ydWK1qSyYesQ3jg+qX0utpz7Pp5Zkrd1Va3KhO7vdCbQLF1IVc8uWudV4ms2jX7ns4fhOr6ytMUXVqCr0HVoYHpQqcLC77hy+dSM6apd6Za8Os3YVRiYlsaq1ANZFEqIh9Kr0J3Lp7MK6DVQifS0id9jf6++YLaqDTb7vKndaQNk1q1ZgnXf2NsgbKLBXHFMNm5T+3RCyjZJVyudWL10vlWZcD13tdKJD57brSwss3rp/BkbpUntzD59LXTOoQ1bhxr6k0usBJBtTEQhbegmorbguAshYLZlqv5ea7MmONmRfZNE2Tqe/D7ezugACJHNTgZPfWxlj9e5dJ1Vl3LAJMzl9zr7o2ttVBf7vG2QpdGq+nu7ceKcRt1pfEKAHIpLu+CSaiKeVO6UuZUZezmPPP6iVZlwObc83239yxs+l0I+hJ3ZRzCGzjk0Ojbe0ObVS+drE+BJso6JKJWGrrOr2zaDTINBp10JAaz75l4A6vD4pEmibLO8S8dM6ualWl4+tHsEHzy321mDMmlrO/YdSrVpGdeUXQN1XDxFbBpsWq1q9Iha41bNZ5VOwoknzGqI3jXh2i90721gcMR6PdM40Z1bZX6yjUfXFZFrsFmlkxILUVetWwYISvNtq7xcCivQVe5BWx57YWozZGR0DOu+ubehOrsK02Do7+3GrQ8PKTv7+IRocOWT/1R2U5eOauqkvu5k8Q0eU+FqU8i+SyRr9LqAfjJx2UCzFWI2hWyrBozLnoL8G9WmbgitylUwAMC82bNwyweWaU1KcXzbp1N8bCSd1KLXc908ta045Dmj8R06m/282bMSC9HVS+dPFZ1xaXO8/+/Yd6ipaQMKKdBVmqTqoY9PCHRQzSdWh8tg0GlXEpX2bQoCMhHX8l03pnSontWNW/bgr779xFTgR5INUNs9+G6gSaTPetyvWSKAGZuhow4Vflz3FKIbYXEPB13RcFdctUkAeM1iP++qVjDvhFmJtD7dJp+tXVS/B19cvMhUmCYPleMAQW++sz1PEz5xDXJTuZVpAwop0F19aoGaMI9rfNIUYhKS0UGtCrSJE9e+ddpCp8VoGr1uUiEeRfesXj82gXXf3IsTT5iVach+HFMe+Kjbpelpu3odRa/pk0PFx8PBNZBEtXJRJUUDpv3GVRCADZf7uVHKdqpWH4A5ilkikEwg+YxViU3JMkV3qzi5Wpn62TfXjasyI9ucNjdOWgop0H01xrhdy/YSPz/wxAwN0SbMJVEt0OZupkInQHY9d1gpJFw6p+lZjU8Iq9009CaOi3dKkg1Im31313OH8fWfvzC1NP/gufbIQ5dQetNKMT4BxFcuOr9xU0bPJIJ1YHBEuQ8URRXFHMUU0GbC9F4ISGRn9u0frx87PrXJ6qs961Z3ulWS7r01K21AIQW6jz2yq1pRDiRdfomBwRHtcl8XIBP9fmCwVnC529DGVRu3KzutToCohIRrWLXPs1Ldj4vg80X3bORKIEmbbUv0h3aPTE2mE0Lgod0j6Dvj1ESCQ37uon2atDOTm61uVZhEsG7att8ozOV5161ZotXij9SFom9fCJky2HZOHeMTYmrF46s9q1Z3BOD957xVWcg9rctwWgrptqgLM49T6SBsuHzZjM9sLmybtplriz678TLcvXaF0g0vWgvU1Eada5brLO4TVr1uzRKty6Ck0qk+QiCb3Cg2t0rX96v6WxVJs+eZBuGi9Y84CxXb6kHlZqsS5klXS66J0/p7u7Hnlotx99oVtVq5EWSAlW/YuuldJ0214Ns/gNqYs8WUqNrT39uND57bPWMMCdQKuS9StDuNy3AICinQpd+ryR7d3VXF2vMWYtO2/TNekClQwBa6G62MYqsFGvXNVaESKD6zuGtkZX+vudQdUPMC0OGax8aVuHcC0Jg/ROUzHZ90bIW4o9gyIPqU3QPMqzQVPu9Vp/Wnyf1tur7qvP293Zh3QmOfkOPEB52POqBOMe3Sv+Q5Q3FytWJU9FS5auLuyLLduvttlpdLYXO5AHobZLTDxL/z3aCRxHOE+ORL0bnqxXNa+HgE6DaxuqoV7Lnl4obPBwZHtLZracvU5UZxyWPjgul9ufjIJ02fasr7Yrs3383xOL55RFz7ig86G3qlk7DpQ405xU19BQDuTpArJ07afEOmc/hi8vuXlb1sbz1tfhYfTLlcnDR0IrqEiPYT0QEiWq/4/hoierz+72dEdE7aRrtgmg1NOcl9IQDXrOyxRmMC07bGKKYseKb70bWVAFx1/sJaIqIYr8euH4381J1PChTXLIG+WprExfShW4abImNtJMmAKIle15SFUlKtdFi1M5M26NpXXIi++3knzMLcyvRwP2VuRSvMTRlDAVhNVS6kyTck70sG70WpVjrxsZU9XhG4JucAOeHayEuudOumKBF1ArgHwB8DGAbwGBFtFUL8KnLYMwD+ixDiVSK6FMB9AM7PosFxdD7Pugds282Po3Md1AWiqJI5+bjNxQOCVBsy16zswW39tVDteEeUG0AqLwyTXVa1QafTfkbHxhNtkNkGcVyTHBkdw7pvzIzGTYLPvdlSLds0wrHxyVRl33xdLHWo8p/Lqlq+bYsjTVWuqyTVaiTp5mH8vqJFz6PlH12DgWycXK3g9TeOW4+T7U6zkgyBi5fLeQAOCCGeBgAi2gzgCgBTAl0I8bPI8TsBLAjZyCR0za1ol1DSX9TmD2xbRsmVQNwrQJW8xyd8Pnp+QB91qQt4snlhqFKvyuvFw7R1AsxUTEN3b7ZBvGHrUINZYHxSYMPWodSDwvXeTANTlwYiTtLqTqpIw6RCwSepVPTcrpqma8CMzhVXl7jLNnHpfNCjY3XVxu1O9xClq1rBG8cnZ5y70kENheJVRDd5W12L1EWgdwN4IfL7MMza958C+L+qL4joOgDXAUBPj3mjLg0DgyP4z6ONs6rM6eDjD2zDlLxHCnqZEyWJ7TlJ1KUUSqZVirQNyuWz6hrr1iyx+oz7dGKb9umSeTCUBmRqi+6e7rhyOTZ9+Byta5/E5gpne2+md+6Ka7+Mvysfl8Cx8Qnc/KB6BeWSTkIVHwKYS9a5mGp8zR/VSueUN5yLoqfzQVflqWlmUBHgJtB1HnqNBxKtRk2g/5HqeyHEfaiZY9DX15fZbqzO71aX0yGNVuSTvOfmB/caS7D5YhOQpo1O+blJAPf36vPYSOHjExlnes4u3g2uk4eL0De1xTQwpf3etiFnS/gWwqxiQrdCjeOSpMwUfzEhhDJ61iWdRPwdbNg6NEMj9plwoqYan0kp7uUT7SeL1z+i/JvXxsaVjgcuJsWszTEuAn0YwMLI7wsAHIwfRETvAvBlAJcKIV4J07xk6B6sKaeDSityeQE+OTp8ii67YJuIXAenSdO65QPLjJqsry1a95xtG3Eml9O4+Ucn9IHGZ6UyqblogWmyM6Y1q7j0Sx9nHFWSMlXyLt27jkfP2nLcA+q8J7q0BNEEeC6ToeoYn0pG0Tb62PlNxzfLHGN1WySiWQB+DeC9AEYAPAbgaiHEUOSYHgDbAXw8Zk/XEsJtUUcIlygfF7v4ANMt1dK0JymuBTskqpJrKgECwGpPds1F41ryTuc+FnXp051LZSMF1Pfr2n90+VF07oAhcO2XPmXhXPqhTevWldNTIdtrmiRMfwfYJ0Ndn/WZRH3dbE3H6+41iQxIVYJOCHGciG4AsA1AJ4CvCCGGiOj6+vf3AvgCgNMA/CPV/IWO6y4YGt3mVdolra8pwWaTV5G1q5MuTappEKm8dFRa9aqN262bg65aiMtzME1IUY3JZDtWkcYraer4+MSWYWiHa7/0iSuQqy2TsJM/67RvmVDM1uejk7wu74mOuNnLhG4fwmeS9V1JmY5vVo4Xp1wuQohHATwa++zeyM+fAvCpoC1zwLR55ZuQK04aP9n4i9UFpKiWbqaB5WqDU2mOJu+COC4bOT5pCmznclk5yPu1CdokeWDibfQZyKr9GumZk4W91NXEpXtWKm8rwC1plfzZN6GYPCau2SZ5V8329/bdoNYd36wcL4VMziUxaSu+wSdxdC/g5GrFuAsvib5YVy8am/3XdUNQtzqIehfY7Jy2gXNyteJc99J2Lps92uQrH3/+Pnsapja6DuSk3iRJGBgc0W5QSjttEldZH+8M0zvQrf50aQt0tu4T5+irNTUryVUSTApXMzbCgYKH/pvshNLmmlQ7UgnGJBsr0fPZNDaT7RZQa2fSBmdyE4si7c22lKo6257rdVzOpTrvwdHpohKmKkQu5wrdRhW+4edpctybUhhcs7JH6dft0jdDpRtIktpBNy504+/EObMS94ssiPY1WyqJUF4uJht6oQV6mhwdgP0Bu252qjbLkrw408AC1JqZz2ZUvK29f/1d5f3E89ZIBgZHnMv6SdLkfpHXTDoIFmnczlRtTBL4JdvnuyJI+kxsCoxP3m6XHDVJJrmQrnnxST4e5NNqAe/y7rNwfCitQNeFxuuq4UQjRFUdxDbQXDSZNAmokmrouu/ixNth84SIe4DoJoA4LhWhXNANGJVniop3fO5RrVnplLmVKUGw6LQqfvabwzOehc89JPFySjLQTf3DJYEUMD152fZR0k7EvtgmApeVkC25Wmih79KmNEnVtOdMm5wrr/T3Nibn0nVqaceUCZFGx8YbNE1bjmyXxElJc28D5lzKpu9cNopOmVtRbkqZePXIONZ9c+9U0I9rFfpoKHaawaPzmnDNzX3V+QuVn696x6kY/MLFeGbjZVi3ZkmDMAf06VFV9PfOTBx2yweWWfN1J9ncW710fkOUX6WDcOTYcWfHmrFxdS59oGbrzjLlqy7xmq1GAeD2vFSJ3pKm6HVpv4sS1Wybf6E3RQH3HB2dRE7L4rQRfiG9Y1QahbTXyfvZtG2/NSpQl5DJpaL5+ISYCuzwQXe/Jptp/HPTM4sHs6jO2XfGqXho9zDGxicBAB0EXH1+z4xKM5u2mQuaxK/lQvQ96ga970AfGKxVXYq3dRLuE61Et2qZFCK4NikxbfjblCCXdySJ9hkf1+Mk7bdVMGtmYQtJ4QV6HJ3QdbVxpo3wS+ueZPKuULmNjYyOGZdZpnTBPtWIQpSE0w1qXTk920R1cHTM4ZyTU8efMKsTfWec2nAOF0K6yyUZ6Lc+PKTswxOGTW2d6YdIHUkaSpuMbhTKvP2q/P1SuOqerXyXPvsTLjEJSd6lLilYXKjbTHVZh/+XTqAnCV2WuAw0mztb1u5Jqo41qTkWUOfakGTl06u7X53GJIs3xz8/YVaHcTLWBbOYzhn3D3fNeeIj7EybZUnqtA4Mjnhp4QRMeT6pPJkIwKxOajA5Jq0bGm1nPP4hWsdVhSlgzLSq7tLsgbnEJETfpauA1Y0VAcyYtK46f6Gy1qi8Vtbh/6UT6IBe6DbDDco3usyXJEJYt8xMEthhw7SJaMr+qOK1sXHctXaFMrzeFsyiO2fcP7zSQagohJvqWq6YIiaT1Gm99WG/giIdRFOCWZVcbVIAb6qXHRy15PJ3JYm3j2yrqg+aJnICsOeWi63C2KZc2QSsiycQAGXxcUCtVGadjbGUAl1F1oI2fi1Xlzdf3+ukQlglTJMG4cRx9ToxaWK6SFr5LHWD1xTM4lIubnxSNLj2rV46P5ELo8Q26fpMyr7aOTBzVabLmf/aWK2fxSfKJALGNSGXrq1x5Cpmx75DqdIMx/cyovtO8nOT7d5WHEaFXAVG8wbZTEchV8ptI9CBMHmmQ/H5gSfwwM7np+xvqjB9wC2nuAsqk4FpkhsYHMFNW/YYN31koYy5hiLTtrbr3OjiWrHu3fmcU0c0HWoIG6dt0jWZb+JmC0WVQSekYDKZHULYmKWWm0SY65CrmBDmS92+k03AuuSl0aGKoB4bn8h87wJoM4GeFwYGR2YIcxWqtLBRbX5OpQOjR8ZxcrWC/zg6DkueLO0g0AnK/t5u7HrusLGd0XTA676xF7c+PGRcYZgmkL4zTk0kSF3PaUpVIAeUaYPVR2M3TbomgfT5gScavI5M79VmKjo4OqYMOpNt0K1ufARMGsFnQpUvPekEq9PETQI2i/0l1bVk0Z1QsEBvAa5uWNHE+Kr6kDKa0xbw01WtJFqZ3Na/fEoo2jwWxienC+3aimboJpCkqyeXc67auF0p0AnTk51u4EcnNZeNLNVSX1aJMiVUe8CjDma10oE7rnyX1TXSJhTTasA2wddB5klJhwCm6pamjbTUbmhq2rXotCp++9rRoKsOHbqiO0lhgd4EfHOSS6SmZNtM0dlJJURI7L2gEpa6Si669jUDm6nE5KUgjzMdE2VsXF8QROI7Qfn4WgPA8UmBXc8dnvpdlxbX1JYQGrCpP0f3Vnxz3gDpKlK5tlGFKtAMqDlR2FJG+2IqupOEQkeKFgGZ/yQareZCdEDabJ0uEZ9pIuTiuC7Jm5Xq1CUiUNfm7sjnPqYGufEY6pn6PqvxCYEHdj4/1Z+kTzTgF+kZj3L1nYBVEcySaL9THVfpIJwytwJAHy8RIvrT1EYVKpHdSYRNHz4HH1vZo6zJmZTQkaQs0DPm1oeHnJNZzZvdqQy9tqUccOmwrukHXHAdIM0Ke3ZJt2BKnWA6xjR4o9dQhbXrQt1VJHlWqnQFIVIuxDHdRzT9horoSi2epmPTh8/B4BcuxrMbL8Nv7nif9llHJztVgJWtb6uuLScSVyaFQH9vN27rX4671q6YOpchbq+B+KFZRJKyySVjTLZt1xS/tt3++NJZN32E0pjj19MlOssi7NknRUD0cxfzguqY1UvnG71ldNGq676xd0aq5ZHRMdy0ZQ9u3LJHaUtfvXS+cgN63uxOzJ7V4ey6mPQdu6axNflq29pkM0PZAoFMLpy2+45f25Y+WteG+LlczI8SOeFm6TbNAr2FuG72uAqj6AZg1tVRVAMkKx9/Xc5pW4qA+P262LWjx8jrmrw4dNGqKkGh21hV5WmROc5v61/ulVU0yTtOk2fFxYXWNTJTp7isXjrfaoNPct/zTpg1Y6P8lLkVXPaut1pdaOPXdTWjNqOGMAv0jOnSuMt1Vf2WfD6bbM2qjhJF1760gj4ubFQblKoUAWnv1zXyUabe9SVqitDlCZERpa4rh6T3bBLaptWPi8uiT2RmkhWSxOe+dSmu5Qaujwuta1wI1e9Xeu5k5SxQ6HzoRUC1tKt01DZYsvQAyToJkAvx4CnAP8+2a87pu9auCHq/rl4ZBDjng1Fhimi15dL2ecemY015/nUaqK6gRvxvo9cx5XPXaa4u76GrWpkKDHMhSTtM2CJlXQvuuGLKh84aesY0M+VA/LqtjIrVBU+NjU9MpeN1eQ4uNuFoioA0RIWeq5ojUPNnjq8QKh2ESeizIUpMvs42M4LK7KWqd2vTjE2263VrligVknVrlmiFWCcRvviRc7Bh6xBurO8bnGKY9Fzs7zqqlU5suHzZjGdgG2u2PZd4tK4ttYXOp7/SUZus410gS5fethXozdRgWy1cW4HNr3pkdAw3btmDWx8eMg4Wm40yhClJlSXQB1USsUon4ehxUx5MM773FV8NudrB+3u77Sa6uHtG/XdTsqr4JGBawZgmLtP7j28uu2YzNE1gqhX1q0fGrX1V5ygwqekCWbn0tqXbYuhKJtHzurqplR3XDmvykR8YHMHh199o+DyJv7WOzw88gZu27EkszIFpgfRGRIAfGZ9MFCEJ+N+XTBmgWg1t2DqkFYjSpgugwa1PXn/Ttv0NbrfjEwKbtu3Xuip2kl8Azuql87Xf6dxN7167osE907VamKryUzQdgq7trx4Zx01b9mCRZnxHffrnnTDL6K6clUtvW2roWaSxbEau4yLhs/uvevYmtzLp/ZEWl5w6NqKCIEROE187ri1lgG2ikv30jiuXK69rKj6h2tj3KSYjMaUT9jFZuriv6jyKZI56XTpmiWsKCJNCk6WDQltq6CErmUhctYN2wTc6L/7sTZqSTgAMDI5gxa3fxaL1j2DR+kfQ+9ffNa6SXMLtTRWfopqsa9/pqla0zyVpJaO0bg2mfqrTJAmNk4WsW6vT3HW4+JC7RLMmrfkrAHxn74tYtXG717NM9NwImRbfbkuB7vLifclikigy8ei8rmoFlU69cOwgmmGq8t0okxp9vGBDtMi1y3miVCuduOr8hU5Lfpe+IzfwokJPThhJzEdJcqXr0D0L3cSsEnxz64mm1q1ZgopH3t9Q5gedeUb6sS9e/4h21Tg6Nh6szoBsi+oZzEqaD9mRtjS5ZOGnnbaWaBlReWHoNh+jqXht9URVz1Sn0Ut7r0pQuiaWcvFL1vkjz5vdiSPHJhr+LoSGFnL1p+unsp0um8bRiFDXv3EZdy4ODNEgsGh2S1c/9qSYnpuqWpSpP4agLQV6Fq6ErQjmKRpSwNtKe8lgIVV2O13+6CSub6p3Fo3QjLfbdm+q/PGTAlNpjn1I435notJBM1ISAOZ+KtvhsmmsC4/X+X13EllXJS57U/FjJoQIsrcRjW+IRykD9vGty4Ka5aq9LQU6EN6VsFX+5kVAJZzkBpwuF4bKFdDkD2zStm3aZ6h3tmPfIaWnSZKSbmnc73TI5we43bNPnVCTcNMpOy4mJhcHhiSRrhKZpEuXOkKVCiJt2t4sV+1tK9CzoB39zW2kCWrxTXeg8oqxVYQJ+c5C7aO4emGpBKUpZ/fcSDEFl3t21W5NhTui10oycbo8U9Mxtklv7uxZzqtr377SilU7C/Sck4cQ/jSkDmpxRGW3dS1eHYpQGpnrxKATlDdqXO98JxaXTWOfvOtJ3oPLM7VFutrqh2a1um7Fqp0Feo4pg2+7TTiF7PStXiGFmpx8JgbVPYeoFWpqB2DXykPh8kxNx8j26dIUyGeSVd9pdp90clskokuIaD8RHSCi9YrviYj+vv7940T07vBNbT/K4Nvu4iLq6mecd+KumkkjWV2KcWT597bzqKI0s8LlmdqO6e/txhc/ck6QZ5J3rBo6EXUCuAfAHwMYBvAYEW0VQvwqctilAM6s/zsfwJfq/zMpKINve7t5/4TQyNKuWkKtevKy0e/qZWQ6Ji/3kjXW9LlEdAGADUKINfXfPwcAQog7Isf8LwA/EEJ8vf77fgDvEUK8qDtvu6TPTUPoNJ+touj7AAyTJ9Kmz+0G8ELk92E0at+qY7oBzBDoRHQdgOsAoKenx+HS7U1ZtNtW27YZpl1wsaGrYlXjar3LMRBC3CeE6BNC9M2fr8+wxtQIZZNlGKY9cNHQhwEsjPy+AMDBBMcwCWDtlmEYV1w09McAnElEi4loNoCPAtgaO2YrgI/XvV1WAnjNZD9nGIZhwmPV0IUQx4noBgDbAHQC+IoQYoiIrq9/fy+ARwG8D8ABAEcAfDK7JjMMwzAqnAKLhBCPoia0o5/dG/lZAPh02KYxDMMwPrRlPnSGYZgywgKdYRimJFgDizK7MNEhAM8l/PM3A/hdwOYUAb7n9oDvuT1Ic89nCCGUft8tE+hpIKJdukipssL33B7wPbcHWd0zm1wYhmFKAgt0hmGYklBUgX5fqxvQAvie2wO+5/Ygk3supA2dYRiGaaSoGjrDMAwTgwU6wzBMSSicQLeVwysqRPQVInqZiJ6MfHYqEX2PiP69/v8pke8+V38G+4loTWtanQ4iWkhEO4joKSIaIqI/r39e2vsmojlE9Asi2lu/51vrn5f2noFa5TMiGiSi79R/L/X9AgARPUtETxDRHiLaVf8s2/sWQhTmH2rJwX4D4O0AZgPYC+DsVrcr0L1dCODdAJ6MfPa3ANbXf14P4M76z2fX7/0EAIvrz6Sz1feQ4J7fCuDd9Z9PAvDr+r2V9r5Rqx1wYv3nCoCfA1hZ5nuu38d/B/B/AHyn/nup77d+L88CeHPss0zvu2ga+nkADgghnhZCHAOwGcAVLW5TEIQQPwJwOPbxFQC+Vv/5awD6I59vFkK8IYR4BrUsl+c1o50hEUK8KIT4Zf3n3wN4CrVKV6W9b1HjP+u/Vur/BEp8z0S0AMBlAL4c+bi092sh0/sumkDXlborK6eLel75+v9vqX9euudARIsA9KKmsZb6vuvmhz0AXgbwPSFE2e/5bgCfBTAZ+azM9ysRAL5LRLvr5TeBjO/bKX1ujnAqddcGlOo5ENGJAB4CcKMQ4j+IVLdXO1TxWeHuWwgxAWAFEXUB+DYRvdNweKHvmYjeD+BlIcRuInqPy58oPivM/cZYJYQ4SERvAfA9ItpnODbIfRdNQ2+3UncvEdFbAaD+/8v1z0vzHIiogpowf0AI8a36x6W/bwAQQowC+AGAS1Dee14F4HIiehY1E+lFRHQ/ynu/UwghDtb/fxnAt1EzoWR630UT6C7l8MrEVgDX1n++FsC/RD7/KBGdQESLAZwJ4BctaF8qqKaK/xOAp4QQ/zPyVWnvm4jm1zVzEFEVwH8FsA8lvWchxOeEEAuEEItQG6/bhRAfQ0nvV0JE84joJPkzgIsBPIms77vVO8EJdo7fh5o3xG8A/FWr2xPwvr4O4EUA46jN1n8K4DQA3wfw7/X/T40c/1f1Z7AfwKWtbn/Ce/4j1JaVjwPYU//3vjLfN4B3ARis3/OTAL5Q/7y09xy5j/dg2sul1PeLmife3vq/ISmrsr5vDv1nGIYpCUUzuTAMwzAaWKAzDMOUBBboDMMwJYEFOsMwTElggc4wDFMSWKAzDMOUBBboDMMwJeH/A7PQQGJCf/piAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(GCN_losses)\n",
    "y = [item.detach().numpy() for item in GCN_losses]\n",
    "\n",
    "\n",
    "plt.scatter(range(epochs), y, label='GCN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f68c83ac-b559-47a9-8fd2-c8fb2641def8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8028490028490028,\n",
       " 0.7927350427350427,\n",
       " 0.8150997150997151,\n",
       " 0.8216524216524217,\n",
       " 0.8250712250712251,\n",
       " 0.8179487179487179,\n",
       " 0.8279202279202279,\n",
       " 0.8162393162393162,\n",
       " 0.8334757834757834,\n",
       " 0.8264957264957264,\n",
       " 0.8367521367521368,\n",
       " 0.834045584045584,\n",
       " 0.8309116809116809,\n",
       " 0.8396011396011396,\n",
       " 0.8344729344729345,\n",
       " 0.8423076923076923,\n",
       " 0.8447293447293447,\n",
       " 0.834045584045584,\n",
       " 0.8415954415954416,\n",
       " 0.846011396011396,\n",
       " 0.8490028490028491,\n",
       " 0.8535612535612536,\n",
       " 0.8525641025641025,\n",
       " 0.8319088319088319,\n",
       " 0.8490028490028491,\n",
       " 0.8443019943019943,\n",
       " 0.8477207977207977,\n",
       " 0.8461538461538461,\n",
       " 0.8498575498575499,\n",
       " 0.848005698005698,\n",
       " 0.8581196581196581,\n",
       " 0.8514245014245014,\n",
       " 0.8374643874643874,\n",
       " 0.8601139601139601,\n",
       " 0.8542735042735042,\n",
       " 0.8676638176638176,\n",
       " 0.8648148148148148,\n",
       " 0.8512820512820513,\n",
       " 0.8521367521367521,\n",
       " 0.860968660968661,\n",
       " 0.8643874643874644,\n",
       " 0.8564102564102564,\n",
       " 0.8650997150997151,\n",
       " 0.8548433048433048,\n",
       " 0.8598290598290599,\n",
       " 0.8663817663817663,\n",
       " 0.8650997150997151,\n",
       " 0.8616809116809117,\n",
       " 0.8669515669515669,\n",
       " 0.861965811965812,\n",
       " 0.8688034188034188,\n",
       " 0.8665242165242165,\n",
       " 0.8666666666666667,\n",
       " 0.8723646723646724,\n",
       " 0.8730769230769231,\n",
       " 0.8735042735042735,\n",
       " 0.8754985754985755,\n",
       " 0.8699430199430199,\n",
       " 0.8759259259259259,\n",
       " 0.8742165242165242,\n",
       " 0.8696581196581197,\n",
       " 0.8736467236467237,\n",
       " 0.8726495726495727,\n",
       " 0.8732193732193733,\n",
       " 0.8797720797720797,\n",
       " 0.870940170940171,\n",
       " 0.8716524216524216,\n",
       " 0.8722222222222222,\n",
       " 0.8732193732193733,\n",
       " 0.8752136752136752,\n",
       " 0.8727920227920228,\n",
       " 0.8753561253561254,\n",
       " 0.882051282051282,\n",
       " 0.8757834757834758,\n",
       " 0.8752136752136752,\n",
       " 0.8804843304843305,\n",
       " 0.8839031339031339,\n",
       " 0.8797720797720797,\n",
       " 0.8826210826210826,\n",
       " 0.8851851851851852,\n",
       " 0.8836182336182337,\n",
       " 0.8811965811965812,\n",
       " 0.8747863247863248,\n",
       " 0.882051282051282,\n",
       " 0.885042735042735,\n",
       " 0.8789173789173789,\n",
       " 0.8817663817663818,\n",
       " 0.8757834757834758,\n",
       " 0.8863247863247863,\n",
       " 0.8792022792022792,\n",
       " 0.8801994301994301,\n",
       " 0.8868945868945869,\n",
       " 0.8886039886039886,\n",
       " 0.8794871794871795,\n",
       " 0.8789173789173789,\n",
       " 0.892022792022792,\n",
       " 0.8836182336182337,\n",
       " 0.8857549857549858,\n",
       " 0.8915954415954416,\n",
       " 0.8896011396011396,\n",
       " 0.8887464387464388,\n",
       " 0.8884615384615384,\n",
       " 0.8935897435897436,\n",
       " 0.8871794871794871,\n",
       " 0.8874643874643875,\n",
       " 0.8893162393162393,\n",
       " 0.8893162393162393,\n",
       " 0.8903133903133903,\n",
       " 0.889031339031339,\n",
       " 0.8796296296296297,\n",
       " 0.8874643874643875,\n",
       " 0.8940170940170941,\n",
       " 0.8870370370370371,\n",
       " 0.8917378917378918,\n",
       " 0.8883190883190883,\n",
       " 0.8883190883190883,\n",
       " 0.8881766381766382,\n",
       " 0.8937321937321937,\n",
       " 0.895014245014245,\n",
       " 0.8931623931623932,\n",
       " 0.8878917378917379,\n",
       " 0.8955840455840456,\n",
       " 0.8924501424501424,\n",
       " 0.8937321937321937,\n",
       " 0.8853276353276354,\n",
       " 0.9009971509971509,\n",
       " 0.8961538461538462,\n",
       " 0.8886039886039886,\n",
       " 0.8891737891737892,\n",
       " 0.9,\n",
       " 0.8958689458689458,\n",
       " 0.8967236467236467,\n",
       " 0.8940170940170941,\n",
       " 0.8911680911680911,\n",
       " 0.8914529914529915,\n",
       " 0.8964387464387464,\n",
       " 0.8843304843304843,\n",
       " 0.8957264957264958,\n",
       " 0.8847578347578348,\n",
       " 0.8908831908831909,\n",
       " 0.8943019943019943,\n",
       " 0.895014245014245,\n",
       " 0.8991452991452992,\n",
       " 0.9015669515669515,\n",
       " 0.9027065527065528,\n",
       " 0.8967236467236467,\n",
       " 0.9015669515669515,\n",
       " 0.8873219373219373,\n",
       " 0.9012820512820513,\n",
       " 0.8984330484330484,\n",
       " 0.8955840455840456,\n",
       " 0.9047008547008547,\n",
       " 0.8972934472934473,\n",
       " 0.9001424501424501,\n",
       " 0.9032763532763532,\n",
       " 0.9041310541310541,\n",
       " 0.9005698005698005,\n",
       " 0.9,\n",
       " 0.8988603988603988,\n",
       " 0.8982905982905983,\n",
       " 0.8988603988603988,\n",
       " 0.9066951566951567,\n",
       " 0.8974358974358975,\n",
       " 0.9027065527065528,\n",
       " 0.8982905982905983,\n",
       " 0.8943019943019943,\n",
       " 0.9,\n",
       " 0.9055555555555556,\n",
       " 0.898005698005698,\n",
       " 0.9015669515669515,\n",
       " 0.9002849002849003,\n",
       " 0.8881766381766382,\n",
       " 0.9066951566951567,\n",
       " 0.8954415954415954,\n",
       " 0.9065527065527066,\n",
       " 0.9051282051282051,\n",
       " 0.8985754985754986,\n",
       " 0.9031339031339032,\n",
       " 0.8968660968660969,\n",
       " 0.9081196581196581,\n",
       " 0.8965811965811966,\n",
       " 0.9001424501424501,\n",
       " 0.9012820512820513,\n",
       " 0.901994301994302,\n",
       " 0.9064102564102564,\n",
       " 0.9064102564102564,\n",
       " 0.8974358974358975,\n",
       " 0.9022792022792023,\n",
       " 0.8935897435897436,\n",
       " 0.903988603988604,\n",
       " 0.8913105413105413,\n",
       " 0.9041310541310541,\n",
       " 0.9079772079772079,\n",
       " 0.9021367521367522,\n",
       " 0.8995726495726496,\n",
       " 0.904985754985755,\n",
       " 0.9008547008547009,\n",
       " 0.9024216524216524,\n",
       " 0.90997150997151,\n",
       " 0.9084045584045584,\n",
       " 0.906980056980057,\n",
       " 0.9082621082621083,\n",
       " 0.8992877492877492,\n",
       " 0.9045584045584045,\n",
       " 0.8857549857549858,\n",
       " 0.9064102564102564,\n",
       " 0.9028490028490028,\n",
       " 0.9085470085470085,\n",
       " 0.908974358974359,\n",
       " 0.9064102564102564,\n",
       " 0.8967236467236467,\n",
       " 0.9028490028490028,\n",
       " 0.9064102564102564,\n",
       " 0.9064102564102564,\n",
       " 0.9098290598290598,\n",
       " 0.9037037037037037,\n",
       " 0.9081196581196581,\n",
       " 0.8935897435897436,\n",
       " 0.9081196581196581,\n",
       " 0.9037037037037037,\n",
       " 0.902991452991453,\n",
       " 0.9066951566951567,\n",
       " 0.9027065527065528,\n",
       " 0.9045584045584045,\n",
       " 0.9034188034188034,\n",
       " 0.9088319088319088,\n",
       " 0.9074074074074074,\n",
       " 0.9071225071225071,\n",
       " 0.9085470085470085,\n",
       " 0.9108262108262108,\n",
       " 0.9038461538461539,\n",
       " 0.9113960113960113,\n",
       " 0.912962962962963,\n",
       " 0.9111111111111111,\n",
       " 0.9102564102564102,\n",
       " 0.911965811965812,\n",
       " 0.9101139601139601,\n",
       " 0.9014245014245015,\n",
       " 0.9095441595441596,\n",
       " 0.9113960113960113,\n",
       " 0.9111111111111111,\n",
       " 0.9101139601139601,\n",
       " 0.9138176638176638,\n",
       " 0.911965811965812,\n",
       " 0.9051282051282051,\n",
       " 0.9118233618233619,\n",
       " 0.9125356125356126,\n",
       " 0.9088319088319088,\n",
       " 0.9061253561253562,\n",
       " 0.9155270655270655,\n",
       " 0.9138176638176638,\n",
       " 0.9121082621082621,\n",
       " 0.9158119658119658,\n",
       " 0.9075498575498575,\n",
       " 0.9142450142450143,\n",
       " 0.9126780626780627,\n",
       " 0.9071225071225071,\n",
       " 0.9058404558404558,\n",
       " 0.912962962962963,\n",
       " 0.9113960113960113,\n",
       " 0.9081196581196581,\n",
       " 0.90997150997151,\n",
       " 0.9125356125356126,\n",
       " 0.9054131054131054,\n",
       " 0.9162393162393162,\n",
       " 0.9034188034188034,\n",
       " 0.9084045584045584,\n",
       " 0.9166666666666666,\n",
       " 0.9111111111111111,\n",
       " 0.9111111111111111,\n",
       " 0.9175213675213675,\n",
       " 0.9188034188034188,\n",
       " 0.9128205128205128,\n",
       " 0.9142450142450143,\n",
       " 0.9165242165242166,\n",
       " 0.9112535612535613,\n",
       " 0.9111111111111111,\n",
       " 0.912962962962963,\n",
       " 0.9084045584045584,\n",
       " 0.9123931623931624,\n",
       " 0.9113960113960113,\n",
       " 0.9136752136752136,\n",
       " 0.9132478632478632,\n",
       " 0.9172364672364672,\n",
       " 0.9160968660968661,\n",
       " 0.9162393162393162,\n",
       " 0.9088319088319088,\n",
       " 0.9145299145299145,\n",
       " 0.9143874643874644,\n",
       " 0.915954415954416,\n",
       " 0.9175213675213675,\n",
       " 0.9148148148148149,\n",
       " 0.9156695156695157,\n",
       " 0.9035612535612536,\n",
       " 0.9054131054131054,\n",
       " 0.9156695156695157,\n",
       " 0.9071225071225071,\n",
       " 0.9162393162393162,\n",
       " 0.9176638176638177,\n",
       " 0.9131054131054132,\n",
       " 0.9196581196581196,\n",
       " 0.9152421652421653,\n",
       " 0.9058404558404558,\n",
       " 0.9135327635327636,\n",
       " 0.9108262108262108,\n",
       " 0.9138176638176638,\n",
       " 0.8995726495726496,\n",
       " 0.9162393162393162,\n",
       " 0.9156695156695157,\n",
       " 0.90997150997151,\n",
       " 0.9085470085470085,\n",
       " 0.9158119658119658,\n",
       " 0.9145299145299145,\n",
       " 0.9109686609686609,\n",
       " 0.9126780626780627,\n",
       " 0.9168091168091168,\n",
       " 0.9160968660968661,\n",
       " 0.9190883190883191,\n",
       " 0.9113960113960113,\n",
       " 0.9142450142450143,\n",
       " 0.9121082621082621,\n",
       " 0.9172364672364672,\n",
       " 0.9118233618233619,\n",
       " 0.9141025641025641,\n",
       " 0.906980056980057,\n",
       " 0.9034188034188034,\n",
       " 0.9092592592592592,\n",
       " 0.9082621082621083,\n",
       " 0.9025641025641026,\n",
       " 0.9135327635327636,\n",
       " 0.9186609686609687,\n",
       " 0.9209401709401709,\n",
       " 0.913960113960114,\n",
       " 0.9182336182336183,\n",
       " 0.9113960113960113,\n",
       " 0.9149572649572649,\n",
       " 0.9202279202279202,\n",
       " 0.9112535612535613,\n",
       " 0.9178062678062678,\n",
       " 0.9176638176638177,\n",
       " 0.9141025641025641,\n",
       " 0.917094017094017,\n",
       " 0.9149572649572649,\n",
       " 0.9183760683760683,\n",
       " 0.9195156695156695,\n",
       " 0.9212250712250712,\n",
       " 0.9192307692307692,\n",
       " 0.9086894586894587,\n",
       " 0.917094017094017,\n",
       " 0.9193732193732194,\n",
       " 0.9158119658119658,\n",
       " 0.915954415954416,\n",
       " 0.9086894586894587,\n",
       " 0.9131054131054132,\n",
       " 0.9186609686609687,\n",
       " 0.91994301994302,\n",
       " 0.92008547008547,\n",
       " 0.9175213675213675,\n",
       " 0.9192307692307692,\n",
       " 0.9105413105413105,\n",
       " 0.9163817663817664,\n",
       " 0.9212250712250712,\n",
       " 0.9195156695156695,\n",
       " 0.9212250712250712,\n",
       " 0.9217948717948717,\n",
       " 0.9216524216524217,\n",
       " 0.9166666666666666,\n",
       " 0.9145299145299145,\n",
       " 0.911965811965812,\n",
       " 0.915954415954416,\n",
       " 0.91994301994302,\n",
       " 0.9166666666666666,\n",
       " 0.9106837606837607,\n",
       " 0.92008547008547,\n",
       " 0.9236467236467236,\n",
       " 0.9160968660968661,\n",
       " 0.9172364672364672,\n",
       " 0.9148148148148149,\n",
       " 0.9210826210826211,\n",
       " 0.9207977207977208,\n",
       " 0.9252136752136753,\n",
       " 0.9195156695156695,\n",
       " 0.9235042735042736,\n",
       " 0.9205128205128205,\n",
       " 0.9223646723646723,\n",
       " 0.9179487179487179,\n",
       " 0.9165242165242166,\n",
       " 0.9163817663817664,\n",
       " 0.9162393162393162,\n",
       " 0.9163817663817664,\n",
       " 0.9149572649572649,\n",
       " 0.916951566951567,\n",
       " 0.9189458689458689,\n",
       " 0.9212250712250712,\n",
       " 0.9225071225071225,\n",
       " 0.9206552706552706,\n",
       " 0.9196581196581196,\n",
       " 0.9237891737891738,\n",
       " 0.9175213675213675,\n",
       " 0.9195156695156695,\n",
       " 0.9196581196581196,\n",
       " 0.9213675213675213,\n",
       " 0.9226495726495727,\n",
       " 0.9183760683760683,\n",
       " 0.922934472934473,\n",
       " 0.9203703703703704,\n",
       " 0.9196581196581196,\n",
       " 0.9152421652421653,\n",
       " 0.9207977207977208,\n",
       " 0.9227920227920228,\n",
       " 0.9162393162393162,\n",
       " 0.9105413105413105,\n",
       " 0.9219373219373219,\n",
       " 0.9183760683760683,\n",
       " 0.9260683760683761,\n",
       " 0.9220797720797721,\n",
       " 0.9179487179487179,\n",
       " 0.9236467236467236,\n",
       " 0.9122507122507123,\n",
       " 0.924074074074074,\n",
       " 0.913960113960114,\n",
       " 0.9209401709401709,\n",
       " 0.9220797720797721,\n",
       " 0.9223646723646723,\n",
       " 0.9217948717948717,\n",
       " 0.9227920227920228,\n",
       " 0.9206552706552706,\n",
       " 0.9172364672364672,\n",
       " 0.9233618233618234,\n",
       " 0.9242165242165242,\n",
       " 0.9213675213675213,\n",
       " 0.9216524216524217,\n",
       " 0.9094017094017094,\n",
       " 0.9254985754985755,\n",
       " 0.924074074074074,\n",
       " 0.9125356125356126,\n",
       " 0.9193732193732194,\n",
       " 0.9132478632478632,\n",
       " 0.9225071225071225,\n",
       " 0.9232193732193732,\n",
       " 0.924074074074074,\n",
       " 0.9209401709401709,\n",
       " 0.9190883190883191,\n",
       " 0.9185185185185185,\n",
       " 0.9209401709401709,\n",
       " 0.92008547008547,\n",
       " 0.9217948717948717,\n",
       " 0.923931623931624,\n",
       " 0.9230769230769231,\n",
       " 0.9237891737891738,\n",
       " 0.9141025641025641,\n",
       " 0.9249287749287749,\n",
       " 0.9237891737891738,\n",
       " 0.9188034188034188,\n",
       " 0.9162393162393162,\n",
       " 0.916951566951567,\n",
       " 0.9206552706552706,\n",
       " 0.9267806267806268,\n",
       " 0.92008547008547,\n",
       " 0.9227920227920228,\n",
       " 0.9245014245014245,\n",
       " 0.9266381766381766,\n",
       " 0.9206552706552706,\n",
       " 0.9175213675213675,\n",
       " 0.9195156695156695,\n",
       " 0.9207977207977208,\n",
       " 0.9279202279202279,\n",
       " 0.9203703703703704,\n",
       " 0.9257834757834758,\n",
       " 0.9190883190883191,\n",
       " 0.924074074074074,\n",
       " 0.9253561253561253,\n",
       " 0.9282051282051282,\n",
       " 0.9149572649572649,\n",
       " 0.9212250712250712,\n",
       " 0.9243589743589744,\n",
       " 0.9276353276353276,\n",
       " 0.9256410256410257,\n",
       " 0.923931623931624,\n",
       " 0.9205128205128205,\n",
       " 0.924074074074074,\n",
       " 0.9205128205128205,\n",
       " 0.9245014245014245,\n",
       " 0.92008547008547,\n",
       " 0.9215099715099715,\n",
       " 0.9237891737891738,\n",
       " 0.9142450142450143,\n",
       " 0.9243589743589744,\n",
       " 0.9215099715099715,\n",
       " 0.9283475783475783,\n",
       " 0.9233618233618234,\n",
       " 0.92008547008547,\n",
       " 0.9183760683760683,\n",
       " 0.9245014245014245,\n",
       " 0.9254985754985755,\n",
       " 0.9156695156695157,\n",
       " 0.9277777777777778,\n",
       " 0.9296296296296296,\n",
       " 0.9287749287749287,\n",
       " 0.9263532763532764]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe4c72ad-29d0-4b4e-9f2b-fda892beb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = iter(loader).next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3eaccdb-4fa2-4490-843a-26c8810daff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ecb3cde-1b24-4a0d-a7d8-a01d53b3b2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a4ca7295-cc25-46b1-9bef-ddf2693e1e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(model, data_i.x.float(), data_i.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0606e67b-b2a0-4018-9fd4-65d138dbb49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6345587293454592\n"
     ]
    }
   ],
   "source": [
    "sub_data = data_list\n",
    "\n",
    "runs = 0\n",
    "correct = 0\n",
    "for data_i in sub_data:\n",
    "    label = data_i.y[0]\n",
    "    \n",
    "    data_i.edge_index\n",
    "    predict = pred(model, data_i.x.float(), data_i.edge_index)\n",
    "    \n",
    "    runs += 1\n",
    "    if label == predict:\n",
    "        correct += 1\n",
    "\n",
    "print('accuracy: ', correct/runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df8da6e-c11e-441c-b403-1331be96969a",
   "metadata": {},
   "source": [
    "### EdgeConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28243742-a0f8-4bf0-9384-20ea899eb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num model params: 7\n"
     ]
    }
   ],
   "source": [
    "model = EdgeConv(2,1)\n",
    "print('num model params:', count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "70fb298b-8b8a-41f6-9c73-8378a743173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([818])) that is different to the input size (torch.Size([818, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (818) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [131]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data_loader, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m model_out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat(), batch\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/functional.py:3261\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3259\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3261\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/functional.py:75\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (818) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    loss = train_one_epoch(model, loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce04098e-36aa-4d4f-93fc-8bcda6534cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2825, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c596e577-9a7d-46b2-a957-12eaa1a7a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab3c9dc4-90d8-4e64-91b9-60624ad60f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Softmax(dim=1)\n",
    "inp = torch.randn(2, 3)\n",
    "output = m(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0b4121b-8fd1-4dbf-a21a-9882229024c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6567, 0.1431, 0.2002],\n",
       "        [0.1342, 0.6416, 0.2242]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9e18af7-dc2c-4378-a3a9-264bed626874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2658, -1.2583, -0.9221],\n",
       "        [ 0.8187,  2.3836,  1.3323]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86cbac-d010-42b6-8d72-9de82e7e4dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
