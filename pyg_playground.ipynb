{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1ce11e47-318b-4293-9c96-d4bda137baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tgn\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09bfa4-93d4-455b-b2ce-56061024d0dd",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e26da9f2-a970-4c08-9f8e-48e6c870e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(2, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c465aa0-7fde-4b4a-a1e6-c2492b8612ae",
   "metadata": {},
   "source": [
    "# Training and Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "835d60e2-6926-4a3f-a974-168da5bf72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer, loss_fn):\n",
    "    \n",
    "    for _, batch in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        model_out = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "        # loss = loss_fn(torch.squeeze(model_out), batch.y.float())\n",
    "        loss = loss_fn(model_out, batch.y)\n",
    "\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f99e97a4-66b6-4ce8-93ec-8383c0f2cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3b38fa63-52ff-48b8-9b6c-b9c2a6307638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x.float(), data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f36fa-7bc9-4f00-8f61-b794918b554d",
   "metadata": {},
   "source": [
    "# Message Passing Pyg Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d22e08a4-3d00-4165-96a2-2f8d995c7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_data = np.fromfile('dataset.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bbeff239-2f3b-48e6-9be5-d85ec1856d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = torch.load('tensor_list.pt')\n",
    "\n",
    "data_list = torch.load('tensor_list_node_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "973f50e7-c083-40f2-8170-871700e50bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list[:int(len(data_list)*0.9)], batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(data_list[:int(len(data_list)*0.9)], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e2e21aff-12f6-4829-88d0-873ee889cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "# *** NOTE on loss function *** I think Cross Entropy Loss requires a different output channel for each class ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a349caf1-c498-40a6-a1d3-e99fbb406818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:06<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "test_scores = []\n",
    "pbar = tqdm(total = epochs, position=0, leave=True)\n",
    "for epoch in range(epochs):\n",
    "    losses.append(train_one_epoch(model, train_loader, optimizer, loss_fn))\n",
    "    test_scores.append(test(test_loader))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7041afdc-ab56-42bd-ac05-b186d72db448",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_losses = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a42942c5-179e-4bca-bfd0-d3447dec2e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598,\n",
       " 0.6337887845146598]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "eb2e2450-a88e-4e59-974c-fbff10930b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 0/50 [03:17<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8f1eb68520>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(GCN_losses)\n",
    "y = [item.detach().numpy() for item in GCN_losses]\n",
    "\n",
    "\n",
    "plt.scatter(range(epochs), y, label='GCN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe4c72ad-29d0-4b4e-9f2b-fda892beb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = iter(loader).next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3eaccdb-4fa2-4490-843a-26c8810daff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ecb3cde-1b24-4a0d-a7d8-a01d53b3b2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a4ca7295-cc25-46b1-9bef-ddf2693e1e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(model, data_i.x.float(), data_i.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0606e67b-b2a0-4018-9fd4-65d138dbb49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6345587293454592\n"
     ]
    }
   ],
   "source": [
    "sub_data = data_list\n",
    "\n",
    "runs = 0\n",
    "correct = 0\n",
    "for data_i in sub_data:\n",
    "    label = data_i.y[0]\n",
    "    \n",
    "    data_i.edge_index\n",
    "    predict = pred(model, data_i.x.float(), data_i.edge_index)\n",
    "    \n",
    "    runs += 1\n",
    "    if label == predict:\n",
    "        correct += 1\n",
    "\n",
    "print('accuracy: ', correct/runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df8da6e-c11e-441c-b403-1331be96969a",
   "metadata": {},
   "source": [
    "### EdgeConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28243742-a0f8-4bf0-9384-20ea899eb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num model params: 7\n"
     ]
    }
   ],
   "source": [
    "model = EdgeConv(2,1)\n",
    "print('num model params:', count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "70fb298b-8b8a-41f6-9c73-8378a743173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxperozek/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([818])) that is different to the input size (torch.Size([818, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (818) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [131]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data_loader, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m model_out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat(), batch\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/modules/loss.py:529\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/nn/functional.py:3261\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3259\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3261\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/comp_gr_thy/lib/python3.9/site-packages/torch/functional.py:75\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (818) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    loss = train_one_epoch(model, loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce04098e-36aa-4d4f-93fc-8bcda6534cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2825, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c596e577-9a7d-46b2-a957-12eaa1a7a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab3c9dc4-90d8-4e64-91b9-60624ad60f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Softmax(dim=1)\n",
    "inp = torch.randn(2, 3)\n",
    "output = m(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0b4121b-8fd1-4dbf-a21a-9882229024c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6567, 0.1431, 0.2002],\n",
       "        [0.1342, 0.6416, 0.2242]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9e18af7-dc2c-4378-a3a9-264bed626874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2658, -1.2583, -0.9221],\n",
       "        [ 0.8187,  2.3836,  1.3323]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86cbac-d010-42b6-8d72-9de82e7e4dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
